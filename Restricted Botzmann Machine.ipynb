{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine \n",
    "\n",
    "Here we will be creating a recommender engine to predict/classify the segment of whether a user will \"like\" or \"not like\" a movie based on the MovieLens Dataset with ratings of the movies. This is a real world dataset with serveral records of ratings by users.\n",
    "\n",
    "We will be using the 100k dataset because the training and test datasets are already split up in the dataset for our purposes here.\n",
    "\n",
    "The [dataset](https://grouplens.org/datasets/movielens/1m/) can be downloaded and checked out from the hyperlink\n",
    "\n",
    "\n",
    "Lets start with Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# For neural network\n",
    "import torch.nn as nn\n",
    "\n",
    "# For Parallel Computing\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all the dataset\n",
    "\n",
    "1. movies is a dataframe of all the movies. here we are importing the 1M dataset\n",
    "    * This dataset is separated by :: so using the appropriate separator\n",
    "    * We have to add header=none becacuse the dataset does not have a dataset\n",
    "    * Engine is to make sure that teh dataset is imported correctly\n",
    "    * Some of the movie characters cocntain special characters. so we use latin-1 as preferred encoding\n",
    "    \n",
    "2. users is a dataframe of all the users\n",
    "\n",
    "3. ratings is a dataframe for all the ratings provided for the movies by the users\n",
    "\n",
    "We are doing this because we want to look at these datasets. We will be using a 100k dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                          movie_name                        genres\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.columns=['movie_id','movie_name','genres']\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>job_id</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  job_id zipcode\n",
       "0        1      F    1      10   48067\n",
       "1        2      M   56      16   70072\n",
       "2        3      M   25      15   55117\n",
       "3        4      M   45       7   02460\n",
       "4        5      M   25      20   55455"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.columns=['user_id','gender','age','job_id','zipcode']\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  ratings  timestamp\n",
       "0        1      1193        5  978300760\n",
       "1        1       661        3  978302109\n",
       "2        1       914        3  978301968\n",
       "3        1      3408        4  978300275\n",
       "4        1      2355        5  978824291"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns=['user_id','movie_id','ratings','timestamp']\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Dataset\n",
    "\n",
    "* Here the files we will be using are tab delimited\n",
    "* In the folder are there are 5 training and test splits. \n",
    "* This is to allow K fold cross validations using 5 folds. In this we are not going to do kfold cross validation but build a straightforward RBM model\n",
    "\n",
    "    1. Using u1.base as training set and u1.test as test set.\n",
    "    2. Training Dataset has 80% of the 100k dataset\n",
    "    3. Test Dataset has the remaining 20000 records\n",
    "    4. Converting both the training set and test set as np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing the training set and the test set\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ..., \n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create two variables with total number of users and movies. THis is because can use all combination of users and movies as input to the restricted boltzmann machine. If a certain combination of user and movie does not have a rating, we can substitute it with a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the number of users and movies\n",
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "Now we need to make a specific structure of data that RBM expect.\n",
    "RBM are a special type of Neural Network which have some input nodes that are the features and there are some observation going through the nn one by one.\n",
    "\n",
    "Here were creating a list of lists with each list corresponds to the each user and in the nested list will have all the ratings for that customer\n",
    "\n",
    "For ex: lets create a list of all the ratings by user 1,2 etc\n",
    "\n",
    "User 1 ratings --> [3.0,1.0,.....,4.0]\n",
    "User 2 ratings --> [2.0,3.0,.....,4.0]\n",
    ".\n",
    ".\n",
    ".\n",
    "User 943 ratings --> [5.0,2.0,.....0.0]\n",
    "\n",
    "Finally put each of this list into another list\n",
    "\n",
    "So we end up with a list of list where all the nested lists correspond to ratings by the corresponding user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Converting the data into an array with users in lines and movies in columns\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the length of the training set. It should be the same as the number of users in our training set=943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the length of each element in the training set\n",
    "This should be equal to number of unique movies - 1682\n",
    "\n",
    "So training set is a list of 943 lists - corresponding to 943 users\n",
    "Each of these 943 lists have a length of 1682 movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building PyTorch Tensors\n",
    "\n",
    "Since RBM is an unsupervised model, the input that it does not need a special label column. What it needs is a speacial list of list vectors that are fed into the input nodes for the model.\n",
    "\n",
    "We implement this using PyTorch Tensors since they are computationally less expensive and converge really fast. Similar to np array, we can convert the whole array into torch arrach using the command as shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Boltzmann Machine, the output and inputs must be consistent. \n",
    "\n",
    "1. In our case, the inputs are ratings from 0 - 5 but we want the ratings in the output to be 0 or 1.\n",
    "2. So to make everything consistent, we have to recode the input parameters based on a judgement to rate a certain threshold and above as \"liked\" =1 and \"not liked\"=0 \n",
    "\n",
    "Here we are using any rating less than 3 as not liked by user and any rating >=3 as liked by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)\n",
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have to build a class to perform the probabilistic graphical model.\n",
    "\n",
    "Lets build this architecture using the following:\n",
    "\n",
    "1. Number of hidden and visible nodes\n",
    "2. Weight\n",
    "3. bias b for visible Node and a for hidden node\n",
    "4. Activation function\n",
    "\n",
    "\n",
    "#### Building a class\n",
    " Initialize -- Initialize all the hidden nodes, varaibles and activation function\n",
    " sample_h --> Probability of Hidden Node given the Visible nodes\n",
    " sample_v --> Probability of Visible Node given the hidden nodes\n",
    " \n",
    "#### Bulding the methods\n",
    "In a RBM, the hidden nodes are randomly sampled \"turned on\" \n",
    "* This sampling is based on Gibbs Sampling. \n",
    "* SO we need to calculate teh probability of a given hidden node to be active given a set of connected visible nodes\n",
    "* All the above is calculated by sample_h\n",
    "* X represents the connected visible nodes to that particular hidden node\n",
    "\n",
    "At the same time the same also happens in the Visible Nodes:\n",
    "* So we calculate the sample_v similar to sample_h\n",
    "\n",
    "#### Contrastive Divergence\n",
    "\n",
    "* Approximating the LogLikelihood Model. \n",
    "* Energy Based Model\n",
    "* Minimizing the energy state of the model\n",
    "* The goal is to minimize the energy by mazimizing the log likelihood. \n",
    "* So instead of calculating the log likelihood, we are appromimating the same\n",
    "* The above is done through the train function\n",
    "    * To do this we pull k iterations of gibbs sample and update the weights, and bias a & b for each iteration\n",
    "    * Here in the first line we update the weights with weight + pv_given_h(0) + pv_given_h(k)\n",
    "    * In the second line we update the bias for visible nodes b\n",
    "    * in the third line we update the bias for hidden nodes a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating the architecture of the Neural Network\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)\n",
    "nv = len(training_set[0])\n",
    "nh = 1000\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the class is created, lets start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atheros/anaconda3/lib/python3.6/site-packages/torch/tensor.py:297: UserWarning: other is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return self.add_(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.404788148712677\n",
      "epoch: 2 loss: 0.2608543483557453\n",
      "epoch: 3 loss: 0.2560392441543844\n",
      "epoch: 4 loss: 0.25326235084890136\n",
      "epoch: 5 loss: 0.25685413780237154\n",
      "epoch: 6 loss: 0.2527687054788823\n",
      "epoch: 7 loss: 0.25348444181146257\n",
      "epoch: 8 loss: 0.24978572319769554\n",
      "epoch: 9 loss: 0.25546859648328357\n",
      "epoch: 10 loss: 0.25897645110409667\n",
      "epoch: 11 loss: 0.2567810300443097\n",
      "epoch: 12 loss: 0.26258069476225804\n",
      "epoch: 13 loss: 0.2573744231337753\n",
      "epoch: 14 loss: 0.25118818633180784\n",
      "epoch: 15 loss: 0.25262101612186405\n",
      "epoch: 16 loss: 0.2629822792814076\n",
      "epoch: 17 loss: 0.2709902809684975\n",
      "epoch: 18 loss: 0.27206881934121346\n",
      "epoch: 19 loss: 0.2703391533954741\n",
      "epoch: 20 loss: 0.26652384638754395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training the RBM\n",
    "nb_epoch = 20\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0 \n",
    "    s = 0.\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user+batch_size]\n",
    "        v0 = training_set[id_user:id_user+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.2441692528394889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing the RBM\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
